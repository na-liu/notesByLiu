**对赛题的理解、数据分析及可视化、算法模型的分析以及一些核心的思路**

[原文链接](http://www.sohu.com/a/139981834_116235)

[数据挖掘类算法](https://www.cnblogs.com/viredery/p/competition_how_to_deal_with_categorical_features.html)

对DMContest的相关记录：

1. Kaggle的类型

- **Featured**：商业或科研难题，奖金一般较为丰厚；
- **Recruitment**：比赛的奖励为面试机会；
- **Research**：科研和学术性较强的比赛，也会有一定的奖金，一般需要较强的领域和专业知识；
- **Playground**：提供一些公开的数据集用于尝试模型和算法；
- **Getting Started**：提供一些简单的任务用于熟悉平台和比赛；
- **In Class**：用于课堂项目作业或者考试。

2. DM基本流程：![1568076470929](C:\Users\娜\AppData\Roaming\Typora\typora-user-images\1568076470929.png)

   比赛设置public leaderboard&private LB，目的是得到一个泛化能力较强的model，避免model过拟合。建模的目标是要获得一个在未知数据上表现良好的model。

3. 比赛过程详解

   ##数据分析：

   #### ◆ **分析特征变量的分布**

   ◇ 特征变量为连续值：如果为**长尾分布**并且考虑使用线性模型，可以对变量进行幂变换或者对数变换。

   > 长尾分布：有点像二八定律，绝大多数冷门的总量加起来要比热门要多很多。数学上不知道是如何应用的。

   ◇ 特征变量为离散值：观察每个离散值的频率分布，对于频次较低的特征，可以考虑统一编码为“其他”类别。

   #### ◆ **分析目标变量的分布**

   ◇ 目标变量为连续值：查看其值域范围是否较大，如果较大，可以考虑对其进行对数变换，并以变换后的值作为新的目标变量进行建模（在这种情况下，需要对预测结果进行逆变换）。一般情况下，可以对连续变量进行Box-Cox变换。通过变换可以使得模型更好的优化，通常也会带来效果上的提升。

   > Box-Cox变换：详见Box-Cox.md

   ◇ 目标变量为离散值：如果数据分布不平衡，考虑是否需要上采样/下采样；如果目标变量在某个ID上面分布不平衡，在划分本地训练集和验证集的时候，需要考虑分层采样（Stratified Sampling）。

   #### ◆ **分析变量之间两两的分布和相关度**

   ◇ 可以用于发现高相关和共线性的特征。

   通过对数据进行探索性分析（甚至有些情况下需要肉眼观察样本），还可以有助于启发数据清洗和特征抽取，譬如缺失值和异常值的处理，文本数据是否需要进行拼写纠正等。

   ##数据清洗

   数据清洗是指对提供的原始数据进行一定的加工，使得其**方便**后续的**特征抽取**。其与特征抽取的界限有时也没有那么明确。常用的数据清洗一般包括：

   #### ◆ 数据的拼接

   ◇ 提供的数据散落在多个文件，需要根据相应的键值进行数据的拼接。

   #### ◆ 特征缺失值的处理

   ◇ 特征值为连续值：按不同的分布类型对缺失值进行补全：偏正态分布，使用均值代替，可以保持数据的均值；偏长尾分布，使用中值代替，避免受 outlier 的影响；

   ◇ 特征值为离散值：使用众数代替。

   #### ◆ 文本数据的清洗

   ◇ 在比赛当中，如果数据包含文本，往往需要进行大量的数据清洗工作。如去除HTML 标签，分词，拼写纠正, 同义词替换，去除停词，抽词干，数字和单位格式统一等。

   ##特征工程

   有一种说法是，特征决定了效果的上限，而不同模型只是以不同的方式或不同的程度来逼近这个上限。这样来看，好的特征输入对于模型的效果至关重要，正所谓”Garbage in, garbage out”。要做好特征工程，往往跟领域知识和对问题的理解程度有很大的关系，也跟一个人的经验相关。特征工程的做法也是Case by Case，以下就一些点，谈谈自己的一些看法。

   #### ◆ 特征变换

   主要针对一些长尾分布的特征，需要进行幂变换或者对数变换，使得模型（LR或者DNN）能更好的优化。需要注意的是，**Random Forest** 和 **GBDT**<梯度提升树> 等模型对单调的函数变换不敏感。其原因在于树模型在求解**分裂点**的时候，只考虑排序分位点。

   #### ◆ 特征编码

   对于离散的类别特征，往往需要进行必要的特征转换/编码才能将其作为特征输入到模型中。常用的编码方式有 LabelEncoder，OneHotEncoder（sklearn里面的接口）。譬如对于”性别”这个特征（取值为男性和女性），使用这两种方式可以分别编码为{0,1}和{[1,0], [0,1]}。

   对于取值较多（如几十万）的类别特征（ID特征），直接进行OneHotEncoder编码会导致特征矩阵非常巨大，影响模型效果。可以使用如下的方式进行处理：

   ◆ 统计每个取值在样本中出现的频率，取 Top N 的取值进行 One-hot 编码，剩下的类别分到“其他“类目下，其中 N 需要根据模型效果进行调优；

   ◆ 统计每个 ID 特征的一些统计量（譬如历史平均点击率，历史平均浏览率）等代替该 ID 取值作为特征，具体可以参考 Avazu 点击率预估比赛第二名的获奖方案；

   ◆ 参考 word2vec 的方式，将每个类别特征的取值映射到一个连续的向量，对这个向量进行初始化，跟模型一起训练。训练结束后，可以同时得到每个ID的Embedding。具体的使用方式，可以参考 Rossmann 销量预估竞赛第三名的获奖方案，entron/entity-embedding-rossmann。

   对于 Random Forest 和 GBDT 等模型，如果类别特征存在较多的取值，可以直接使用 LabelEncoder 后的结果作为特征。

   ##模型训练和验证

   #### ◆ 模型选择

   在处理好特征后，我们可以进行模型的训练和验证。

   ◆ 对于**稀疏型**特征（如文本特征，One-hot的ID类特征），我们一般使用**线性模型**，譬如 Linear Regression 或者 Logistic Regression。Random Forest 和 GBDT 等树模型不太适用于稀疏的特征，但可以先对特征进行降维（如PCA，SVD/LSA等），再使用这些特征。稀疏特征直接输入 DNN 会导致网络 weight 较多，不利于优化，也可以考虑先**降维**，或者对 ID 类特征使用 Embedding 的方式；

   ◆ 对于**稠密型**特征，推荐使用 **XGBoost** 进行建模，简单易用效果好；

   ◆ 数据中既有稀疏特征，又有稠密特征，可以考虑使用**线性模型**对稀疏特征进行建模，将其输出与稠密特征一起再输入 XGBoost/DNN 建模，具体可以参考2.5.2节 Stacking 部分。

   #### ◆ 调参和模型验证

   对于选定的特征和模型，我们往往还需要对模型进行超参数的调优，才能获得比较理想的效果。调参一般可以概括为以下三个步骤：

   **训练集和验证集的划分**。根据比赛提供的训练集和测试集，模拟其划分方式对训练集进行划分为本地训练集和本地验证集。划分的方式视具体比赛和数据而定，常用的方式有：

   a) 随机划分：譬如随机采样 70% 作为训练集，剩余的 30% 作为测试集。在这种情况下，本地可以采用 KFold 或者 Stratified KFold 的方法来构造训练集和验证集。

   b) 按时间划分：一般对应于时序序列数据，譬如取前 7 天数据作为训练集，后 1 天数据作为测试集。这种情况下，划分本地训练集和验证集也需要按时间先后划分。常见的错误方式是随机划分，这种划分方式可能会导致模型效果被高估。

   c) 按某些规则划分：在 HomeDepot 搜索相关性比赛中，训练集和测试集中的 Query 集合并非完全重合，两者只有部分交集。而在另外一个相似的比赛中（CrowdFlower 搜索相关性比赛），训练集和测试集具有完全一致的 Query 集合。对于 HomeDepot 这个比赛中，训练集和验证集数据的划分，需要考虑 Query 集合并非完全重合这个情况，其中的一种方法可以参考第三名的获奖方案，https://github.com/ChenglongChen/Kaggle_HomeDepot。

   **指定参数空间**。在指定参数空间的时候，需要对模型参数以及其如何影响模型的效果有一定的了解，才能指定出合理的参数空间。譬如DNN或者XGBoost中学习率这个参数，一般就选 0.01 左右就 OK 了（太大可能会导致优化算法错过最优化点，太小导致优化收敛过慢）。再如 Random Forest，一般设定树的棵数范围为 100~200 就能有不错的效果，当然也有人固定数棵数为 500，然后只调整其他的超参数。

   **按照一定的方法进行参数搜索**。常用的参数搜索方法有，Grid Search，Random Search以及一些自动化的方法（如 Hyperopt）。其中，Hyperopt 的方法，根据历史已经评估过的参数组合的效果，来推测本次评估使用哪个参数组合更有可能获得更好的效果。有关这些方法的介绍和对比，可以参考文献 [2]。

   