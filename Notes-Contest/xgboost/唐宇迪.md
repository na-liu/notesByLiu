xgboost是竞赛类题目很常见的算法，可以得到一个不错的准确度，与决策树算法相结合。决策树可以做分类问题，同样也可以做回归问题。

XGBoost是属于boosting的一种，就是将多个弱分类器集成为一个强分类器的方法。

###公式推理

![1568107007754](C:\Users\娜\AppData\Roaming\Typora\typora-user-images\1568107007754.png)

![1568107145348](C:\Users\娜\AppData\Roaming\Typora\typora-user-images\1568107145348.png)

决策树的叶子节点数越多，过拟合的风险越大，所以要对叶子节点的数目进行限制。![1568107255205](C:\Users\娜\AppData\Roaming\Typora\typora-user-images\1568107255205.png)

所以，目标函数=惩罚项+原目标函数![1568107452532](C:\Users\娜\AppData\Roaming\Typora\typora-user-images\1568107452532.png)![1568107520874](C:\Users\娜\AppData\Roaming\Typora\typora-user-images\1568107520874 .png)

### 安装

在anaconda环境下，只需要打开anaconda prompt，输入pip install xgboost即可。

### 实战

1. 读取文件：numpy.loadtxt读取csv文件，delimiter分隔符为‘，’![1568126935633](C:\Users\娜\AppData\Roaming\Typora\typora-user-images\1568126935633.png)

2. 划分数据集：into X/Y![1568126921057](C:\Users\娜\AppData\Roaming\Typora\typora-user-images\1568126921057.png)

3. 划分训练集和测试集：测试比例![1568126813351](C:\Users\娜\AppData\Roaming\Typora\typora-user-images\1568126813351.png)

   <img src="C:\Users\娜\AppData\Roaming\Typora\typora-user-images\1568126841824.png" alt="1568126841824" style="zoom: 200%;" />

4. 构建XGBoost模型并且使用测试集：XGBClassifier![1568127169879](C:\Users\娜\AppData\Roaming\Typora\typora-user-images\1568127169879.png)

5. 评估模型的精度：![1568127097217](C:\Users\娜\AppData\Roaming\Typora\typora-user-images\1568127097217.png)![1568127142279](C:\Users\娜\AppData\Roaming\Typora\typora-user-images\1568127142279.png)

